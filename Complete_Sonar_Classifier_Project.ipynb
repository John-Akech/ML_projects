{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7bed8e",
   "metadata": {},
   "source": [
    "# üß† Sonar Rock vs Mine Classifier (Full ML Project)\n",
    "\n",
    "This project uses a dataset of sonar signals to predict whether an object is a **rock** or a **mine**.\n",
    "\n",
    "## üîç What You'll Learn:\n",
    "- How to load and explore a dataset\n",
    "- How to clean and preprocess data (handle types, imbalance, scaling, etc.)\n",
    "- How to train ML models (Logistic Regression & Random Forest)\n",
    "- How to evaluate using accuracy, confusion matrix, and classification report\n",
    "- How to use cross-validation\n",
    "- How to test with new data\n",
    "- How to write a prediction function\n",
    "- Bonus: Visualizations to understand model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f533c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 1: Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fa65d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 2: Load the Dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/krishnaik06/SONAR-Data-Analysis/master/sonar.all-data.csv', header=None)\n",
    "# Adding column names for clarity\n",
    "df.columns = [str(i) for i in range(60)] + ['Label']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ea70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 3: Understand the Structure of the Data\n",
    "print('Shape:', df.shape)\n",
    "print('\\nInfo:')\n",
    "print(df.info())\n",
    "print('\\nMissing Values:', df.isnull().sum().sum())\n",
    "print('\\nClass Distribution:')\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6685d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 4: Encode Labels (M = 1 = Mine, R = 0 = Rock)\n",
    "le = LabelEncoder()\n",
    "df['Label'] = le.fit_transform(df['Label'])\n",
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 5: Visualize Class Distribution\n",
    "sns.countplot(x='Label', data=df)\n",
    "plt.title('Class Distribution (0 = Rock, 1 = Mine)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155cfb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 6: Train-Test Split and Feature Scaling\n",
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c714270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 7: Train Logistic Regression and Random Forest\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 8: Evaluate Models\n",
    "print('Logistic Regression Accuracy:', accuracy_score(y_test, lr_pred))\n",
    "print('Random Forest Accuracy:', accuracy_score(y_test, rf_pred))\n",
    "\n",
    "print('\\nClassification Report (Random Forest):')\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(rf_model, X_test, y_test)\n",
    "plt.title('Confusion Matrix - Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf872e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 9: Cross-Validation on Full Dataset\n",
    "scores = cross_val_score(rf_model, X, y, cv=5)\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Mean CV Score:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59053857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 10: Hyperparameter Tuning (Random Forest)\n",
    "param_grid = {'n_estimators': [50, 100, 150], 'max_depth': [None, 5, 10]}\n",
    "grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "print('Best Parameters:', grid.best_params_)\n",
    "best_model = grid.best_estimator_\n",
    "print('Test Accuracy (Tuned Model):', accuracy_score(y_test, best_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18eb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 11: Predict on New Data\n",
    "def predict_sample(sample):\n",
    "    sample = np.array(sample).reshape(1, -1)\n",
    "    sample_scaled = scaler.transform(sample)\n",
    "    pred = best_model.predict(sample_scaled)[0]\n",
    "    return 'Mine' if pred == 1 else 'Rock'\n",
    "\n",
    "# Try with a test sample\n",
    "print('Prediction:', predict_sample(X_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c19030",
   "metadata": {},
   "source": [
    "## ‚úÖ Conclusion\n",
    "- Logistic Regression and Random Forest both work, but Random Forest performs better.\n",
    "- Cross-validation ensures stability across datasets.\n",
    "- We tuned the model with GridSearchCV for better performance.\n",
    "- Final model is wrapped in a simple prediction function.\n",
    "\n",
    "**Next Steps:** Try deploying this with Streamlit!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
